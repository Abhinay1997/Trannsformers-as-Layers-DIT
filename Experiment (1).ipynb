{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a81119-844c-4e6b-b1cb-f0aae0f5b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/diffusers.git\n",
    "# use the 803e817 commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb297b46-08d8-4ed7-affa-98f65ef94f9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub transformers datasets accelerate sentencepiece einops protobuf matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bf130-bd2d-4e5c-8708-c5a445795a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a7b69-b5b4-4eee-8107-8532eed6913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0ca93-26d7-4414-bb71-cdff387e0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb565587-b099-4c3f-9d37-7a61e45eb5d6",
   "metadata": {},
   "source": [
    "## Setup the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a839104-7037-4408-a19c-8e567062b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_expt = [\n",
    "    \"A charismatic speaker is captured mid-speech. He has short, tousled brown hair that’s slightly messy on top. He has a round circle face, clean shaven, adorned with rounded rectangular-framed glasses with dark rims, is animated as he gestures with his left hand. He is holding a black microphone in his right hand, speaking passionately. The man is wearing a light grey sweater over a white t-shirt. He’s also wearing a simple black lanyard hanging around his neck. The lanyard badge has the text “Anakin AI”. Behind him, there is a blurred background with a white banner containing logos and text (including Anakin AI), a professional conference setting.\", #Anakin AI\n",
    "    \"a red dog wearing a blue hat sits with a yellow cat wearing pink sunglasses\", #wonderflex on reddit.\n",
    "    \"A Samsung LED moniter's screen on a table displays an image of a garden with signboard mentions 'All is Well', A teddy toy placed on the table, a cat is sleeping near the teddy toy, a mushroom dish on red plate placed on the table, raining outside, a parrot sitting on the nearby window, a flex banner with text 'Enjoy the life' visible from outside of the window,\"\n",
    "    \"3d model of a green war balloon, clash of clans, fantasy game, front view, game asset, detailed, war ready, photorealistic, in a war enviroment, spring, disney style, pixar style\",\n",
    "    \"Photo of a felt puppet diorama scene of a tranquil nature scene of a secluded forest clearing with a large friendly, rounded robot is rendered in a risograph style. An owl sits on the robots shoulders and a fox at its feet. Soft washes of color, 5 color, and a light-filled palette create a sense of peace and serenity, inviting contemplation and the appreciation of natural beauty.\",\n",
    "    \"The Golden gate bridge\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d586cf2-ef31-46c2-aa8b-63055aa7c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_expt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4762e-a191-476a-80ae-65e4172bc734",
   "metadata": {},
   "source": [
    "## Load the flux model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194933e8-ad5a-4d7e-84af-ac833b6adc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from utils import plot_image_grid, cosine_similarity, plot_similarity_matrix\n",
    "from custom_flux_pipeline import FluxPipeline\n",
    "from custom_flux_transformer import FluxTransformer2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdb698-d7e5-42d0-a675-bacfe19f3ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expt_transformer = FluxTransformer2DModel.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16, subfolder=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01e28c-87c5-4678-8038-962132c61b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = FluxPipeline.from_pretrained(\n",
    "        \"black-forest-labs/FLUX.1-schnell\",\n",
    "        transformer=expt_transformer,\n",
    "        torch_dtype=torch.bfloat16\n",
    "        )\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f4954-0db5-4d54-bb22-d661087b552f",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Is there a common representation space for the diffusion transformer as shown for other transformers in [Transformer layers as painters](https://arxiv.org/pdf/2407.09298) ?\n",
    "\n",
    "### Test: \n",
    "1. Collect the hidden states of the transformer for each layer at each timestep across multiple inputs.\n",
    "2. Test #1: Avg the hidden states of the layers across inputs.\n",
    "3. Test #2: Avg the hidden states of the layers across timesteps. (Intutively should give same result as for a single timestep a.k.a shouldn't vary too much)\n",
    "4. Test #3: Avg the hidden states of the layers across inputs and timesteps.\n",
    "5. Compute the cosine similarity using the average hidden states (activations) of each layer from the step above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3b996-c422-4078-83fc-a2ec94c1d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flux(prompts, layer_order, single_layer_order):\n",
    "    results = []\n",
    "    print(f\"layer_order {layer_order}\")\n",
    "    print(f\"single_layer_order {single_layer_order}\")\n",
    "    generator = torch.Generator('cpu')\n",
    "    generator.manual_seed(19943434)\n",
    "    for prompt in prompts:\n",
    "        out, encoder_actns, actns, single_actns = pipe(\n",
    "            prompt=prompt,\n",
    "            guidance_scale=0.,\n",
    "            height=768,\n",
    "            width=1360,\n",
    "            num_inference_steps=4,\n",
    "            max_sequence_length=256,\n",
    "            return_dict=True,\n",
    "            layer_order=layer_order,\n",
    "            single_layer_order=single_layer_order,\n",
    "            generator=generator\n",
    "        )\n",
    "        results.append((prompt, out.images[0]))\n",
    "    plot_image_grid(results, rows=len(prompts), cols=1, figsize=(30,25))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a220417c-92e2-48e9-a167-ce7a0758b1de",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cf60f-8693-4980-87f6-1daef0c4a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_actns_sims = []\n",
    "actns_cos_sims = []\n",
    "single_actns_cos_sims = []\n",
    "results = []\n",
    "\n",
    "generator = torch.Generator('cpu')\n",
    "generator.manual_seed(19943434)\n",
    "for prompt in test_prompts_expt:\n",
    "    out, encoder_actns, actns, single_actns = pipe(\n",
    "        prompt=prompt,\n",
    "        guidance_scale=0.,\n",
    "        height=768,\n",
    "        width=1360,\n",
    "        num_inference_steps=4,\n",
    "        max_sequence_length=256,\n",
    "        return_dict=True,\n",
    "        layer_order=list(range(len(expt_transformer.transformer_blocks))),\n",
    "        single_layer_order=list(range(len(expt_transformer.single_transformer_blocks))),\n",
    "        generator=generator\n",
    "    )\n",
    "    results.append((prompt, out.images[0]))\n",
    "    encoder_actns_sims.append(cosine_similarity(encoder_actns, compute_mean=True))\n",
    "    actns_cos_sims.append(cosine_similarity(actns, compute_mean=True))\n",
    "    single_actns_cos_sims.append(cosine_similarity(single_actns, compute_mean=True))\n",
    "\n",
    "encoder_actns_sims = torch.stack(encoder_actns_sims, dim=0)\n",
    "actns_cos_sims = torch.stack(actns_cos_sims, dim=0)\n",
    "single_actns_cos_sims = torch.stack(single_actns_cos_sims, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e671f5-edc8-419b-9420-2cefa7f0d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(einops.reduce(encoder_actns_sims, 'i a b -> a b', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acaeb4-04d9-483d-856c-135dc2e959cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(einops.reduce(actns_cos_sims, 'i a b -> a b', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011a6ad-3af6-4e1a-88de-bbddb2a86d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(einops.reduce(single_actns_cos_sims, 'i a b -> a b', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e57b8d-0307-4bf6-8392-5a66bcd8f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_grid(results, rows=4, cols=1, figsize=(30,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba96e5f-70ee-426c-96b8-18ed1aabd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skipping middle layers of the transformer blocks seems to affect prompt adherence.\n",
    "### Eg: An antique chest with 3 drawers, A red circle on top a blue square. -> Retest this.\n",
    "## Skipping middle layers of the single transformer blocks seem to affect \n",
    "# [0,1,2,3] -> base\n",
    "# [0,2,3] -> skip \n",
    "# [0,1,1,3] -> skip-repeat\n",
    "# [0,(1,2),3] -> parallel\n",
    "# [3,2,1,0] -> reverse \n",
    "# [0, (1,2), (1,2), 3] -> looped-parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b89a7c-292e-4aed-b5f5-8df53430eb2c",
   "metadata": {},
   "source": [
    "## Skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50be2a-b199-47e2-8caf-fd50554c2727",
   "metadata": {},
   "source": [
    "### Skipping middle transformer_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d54b4b-739b-4eae-af21-4051baebe8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = [0,1,2,3,4,5,6,11,12,13,14,15,16,17,18] #skipping 7,8,9,10 layers\n",
    "single_layer_order = list(range(len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_transformer = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d230faf-04fc-443b-9652-aa601b2779cd",
   "metadata": {},
   "source": [
    "### Skipping middle single transformer blocks\n",
    "There seem to be two groupings in the middle layers. one group till layer 16-17 and another group till layer 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb08f8-86b9-4480-8adf-ad543f852f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(10)) + list(range(14,len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_single_layers = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b81c8a-6e93-4c10-90d3-17024b5a3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(22)) + list(range(27,len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_single_layers_later = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a1338-f75e-4c8d-a990-238398635512",
   "metadata": {},
   "source": [
    "### Skipping first and last layers: transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c041a93-e292-49e2-ad31-81e75d6bbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(1,len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(0,len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_layers_first = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b04cd-1a96-4c33-9755-51181581198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)-1))\n",
    "single_layer_order=list(range(0,len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_layers_last = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b8fd3-af38-48bb-bd7d-181d025559c2",
   "metadata": {},
   "source": [
    "### Skipping first and last layers: single transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3beed-8b37-41a5-9dfe-9db0e6537979",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(1,len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_skip_single_layers_first = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560aae3-94cb-4937-a2e6-e74a03bcbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(len(expt_transformer.single_transformer_blocks)-1))\n",
    "results_skip_single_layers_last = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30dc03-3d28-4a8a-b018-846dc37a388e",
   "metadata": {},
   "source": [
    "## Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ad0c2-a499-47d1-804e-d1bc41a11c24",
   "metadata": {},
   "source": [
    "### Repeat transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8bd77-5bb8-4aa3-9416-1771a6b435fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=[9 if 3 <= i <= 16 else i for i in range(len(expt_transformer.transformer_blocks))]\n",
    "single_layer_order=list(range(len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_layer_repeat = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d1d60-cbb4-42d8-b17a-2f6a52ea7673",
   "metadata": {},
   "source": [
    "### Repeat single transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485818f-e87b-4039-bbee-73c97cb3a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=[19 if 4 <= i <= 35 else i for i in range(len(expt_transformer.single_transformer_blocks))]\n",
    "\n",
    "results_single_layer_repeat = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668d130-7cd7-4289-9857-615cdedc5059",
   "metadata": {},
   "source": [
    "## Reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e14a6-eb4f-48eb-b8f0-adc26f825e9b",
   "metadata": {},
   "source": [
    "### Reverse transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaef68f-335e-4808-bbcf-963d57ab8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=[0,1,2] + list(reversed(list(range(3,len(expt_transformer.transformer_blocks)-3)))) + list(range(len(expt_transformer.transformer_blocks)-3, len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_mid_layer_reverse = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb38fcc-0dd1-4525-a752-8a4e6000644f",
   "metadata": {},
   "source": [
    "### Reverse single transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e0ae3-41e4-44e5-af8b-03bc5fa9843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order=list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=[0,1,2,3,4] + list(reversed(list(range(5, len(expt_transformer.single_transformer_blocks)-4)))) + list(range(len(expt_transformer.single_transformer_blocks)-4, len(expt_transformer.single_transformer_blocks)))\n",
    "\n",
    "results_mid_single_layer_reverse = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc9d14-3696-41c4-8eb3-950e73d7d185",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17576a6c-ad01-4f5a-ba88-a301b36caabf",
   "metadata": {},
   "source": [
    "### Parallel: transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2c44c-263b-4864-85ee-d06b26b31828",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = [0, 1, 2] + [tuple(range(3,16))] + list(range(17,len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(len(expt_transformer.single_transformer_blocks)))\n",
    "results_parallel_transformer = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c148e1-7ab0-4da5-bacf-9b752c6807ef",
   "metadata": {},
   "source": [
    "### Parallel: single transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2cc943-151a-4517-b974-5019ea86d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=[0,1,2,3] + [tuple(range(4, len(expt_transformer.single_transformer_blocks)-4))] + list(range(len(expt_transformer.single_transformer_blocks)-4,len(expt_transformer.single_transformer_blocks)))\n",
    "results_parallel_single_transformer = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc8b10-fdae-4545-ac5c-eeeac69fed87",
   "metadata": {},
   "source": [
    "## Looped-Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c69fe6-1fe2-4996-8b4a-da37a94d2a26",
   "metadata": {},
   "source": [
    "### Looped Parallel: transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a93f4-b6bf-4b55-a513-aeea88efe267",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_layers = tuple(range(3,16))\n",
    "layer_order = [0, 1, 2] + [parallel_layers]*len(parallel_layers) + list(range(17,len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=list(range(len(expt_transformer.single_transformer_blocks)))\n",
    "results_parallel_transformer_looped = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f66c0-4110-49ee-b13c-45647b3bbdec",
   "metadata": {},
   "source": [
    "### Looped Parallel: single transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aea753-0f30-46d5-92f1-1251761391f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parallel_layers = tuple(range(4, len(expt_transformer.single_transformer_blocks)-4))\n",
    "layer_order = list(range(len(expt_transformer.transformer_blocks)))\n",
    "single_layer_order=[0,1,2,3] + [parallel_layers]*len(parallel_layers) + list(range(len(expt_transformer.single_transformer_blocks)-4,len(expt_transformer.single_transformer_blocks)))\n",
    "results_parallel_single_transformer_looped = test_flux(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458f989-707d-45f2-994d-313a67f90cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "import textwrap\n",
    "prompts = []\n",
    "images = []\n",
    "titles = [\n",
    "    \"Baseline\", \"Repeat parallel and avg MMDiT middle layers\", \"Repeat parallel and avg Single middle layers\"\n",
    "]\n",
    "for item in zip(\n",
    "        results,\n",
    "        results_parallel_transformer,\n",
    "        results_parallel_single_transformer,\n",
    "    ):\n",
    "    prompts.append(item[0][0])\n",
    "    images.append([i[1] for i in item])\n",
    "\n",
    "num_rows = len(prompts)\n",
    "num_cols = len(images[0])\n",
    "fig, axes = pyplot.subplots(num_rows, num_cols, figsize=(30, 25), constrained_layout=True)\n",
    "\n",
    "# Plot the images in the grid\n",
    "for i, row_images in enumerate(images):\n",
    "    for j, image in enumerate(row_images):\n",
    "        axes[i, j].imshow(image)  # Display the image\n",
    "        axes[i, j].axis('off')  # Hide the axes\n",
    "        if i == 0:\n",
    "            axes[0,j].set_title(titles[j], fontsize=24)\n",
    "    # wrapped_text = \"\\n\".join(textwrap.wrap(prompts[i], width=200))\n",
    "    # # Set the row title by merging the column cells\n",
    "    # axes[i, num_cols // 2 - 1].set_title(wrapped_text, fontsize=16, pad=0)\n",
    "\n",
    "# Adjust layout\n",
    "# pyplot.show()\n",
    "pyplot.savefig('image_eight.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f044fc-2283-4a5b-9e30-955633604e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
