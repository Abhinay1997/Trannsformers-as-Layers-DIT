{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cf86c-6089-4ad9-8430-bbb370b5ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab7ffa-b9fc-45d0-adf2-99c2f65f6831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub transformers datasets accelerate sentencepiece einops protobuf matplotlib accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdb8e7-c968-419f-8844-425810a0d7df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83de97-2eff-477f-a187-d38478a3e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287b9a8-9d6c-4ef4-ae87-564954220c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291044e-004e-4a60-a269-f6b7c80ae14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_expt = [\n",
    "    \"A charismatic speaker is captured mid-speech. He has short, tousled brown hair that’s slightly messy on top. He has a round circle face, clean shaven, adorned with rounded rectangular-framed glasses with dark rims, is animated as he gestures with his left hand. He is holding a black microphone in his right hand, speaking passionately. The man is wearing a light grey sweater over a white t-shirt. He’s also wearing a simple black lanyard hanging around his neck. The lanyard badge has the text “Anakin AI”. Behind him, there is a blurred background with a white banner containing logos and text (including Anakin AI), a professional conference setting.\", #Anakin AI\n",
    "    \"a red dog wearing a blue hat sits with a yellow cat wearing pink sunglasses\", #wonderflex on reddit.\n",
    "    \"A Samsung LED moniter's screen on a table displays an image of a garden with signboard mentions 'All is Well', A teddy toy placed on the table, a cat is sleeping near the teddy toy, a mushroom dish on red plate placed on the table, raining outside, a parrot sitting on the nearby window, a flex banner with text 'Enjoy the life' visible from outside of the window,\"\n",
    "    \"3d model of a green war balloon, clash of clans, fantasy game, front view, game asset, detailed, war ready, photorealistic, in a war enviroment, spring, disney style, pixar style\",\n",
    "    \"Photo of a felt puppet diorama scene of a tranquil nature scene of a secluded forest clearing with a large friendly, rounded robot is rendered in a risograph style. An owl sits on the robots shoulders and a fox at its feet. Soft washes of color, 5 color, and a light-filled palette create a sense of peace and serenity, inviting contemplation and the appreciation of natural beauty.\",\n",
    "    \"The Golden gate bridge\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a289bf-19ce-4d51-868a-83970f4f91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from utils import plot_image_grid, cosine_similarity, plot_similarity_matrix\n",
    "from custom_auraflow_pipeline import AuraFlowPipeline\n",
    "from custom_auraflow_transformer import AuraFlowTransformer2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7a886-82ba-45e3-bfab-66fb462ff2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_transformer = AuraFlowTransformer2DModel.from_pretrained(\"fal/AuraFlow-v0.3\", torch_dtype=torch.float16, subfolder=\"transformer\", variant=\"fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f398fa-29bd-4124-9021-7433b800a2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = AuraFlowPipeline.from_pretrained(\n",
    "        \"fal/AuraFlow-v0.2\",\n",
    "        transformer=expt_transformer,\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "        )\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_sequential_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3f94b-180f-44df-910b-b3596853f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_aura(prompts, layer_order,single_layer_order):\n",
    "    results = []\n",
    "    print(f\"layer_order {layer_order}\")\n",
    "    print(f\"single_layer_order {single_layer_order}\")\n",
    "    generator = torch.Generator('cpu')\n",
    "    generator.manual_seed(19943434)\n",
    "    for prompt in prompts:\n",
    "        out, _, _, _ = pipe(\n",
    "            prompt=prompt,\n",
    "            height=1024,\n",
    "            width=1024,\n",
    "            num_inference_steps=50,\n",
    "            guidance_scale=3.5,\n",
    "            max_sequence_length=256,\n",
    "            return_dict=True,\n",
    "            layer_order=layer_order,\n",
    "            single_layer_order=single_layer_order,\n",
    "            generator=generator\n",
    "        )\n",
    "        results.append((prompt, out.images[0]))\n",
    "    plot_image_grid(results, rows=len(prompts), cols=1, figsize=(25,25))\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2f8fa-7d7c-4ef6-a838-018e6a01d9a7",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee14cf-7ea5-4adc-8ecb-f40593966396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# tensor = steps x layers x batch x a x b\n",
    "def cosine_similarity(tensor, compute_mean=False):\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "\n",
    "    if compute_mean:\n",
    "        # Step 1: Compute the average along the 's' dimension -> shape becomes (l, b, a, c)\n",
    "        averaged_tensor = einops.reduce(tensor, 's l b a c -> l b a c', 'mean')\n",
    "    else:\n",
    "        averaged_tensor = tensor\n",
    "    # Step 2: Reshape (b, a, c) into a single dimension -> shape becomes (l, a*b*c)\n",
    "    reshaped_tensor = einops.rearrange(averaged_tensor, 'l a b c -> l (a b c)')\n",
    "\n",
    "    # Step 3: Compute cosine similarity between each pair in the 'l' dimension\n",
    "    # Cosine similarity: (x * y) / (||x|| * ||y||)\n",
    "    # Here, we compute pairwise cosine similarities using PyTorch's F.cosine_similarity\n",
    "    layers = reshaped_tensor.size()[0]\n",
    "    # Initialize a similarity matrix\n",
    "    cosine_similarities = torch.zeros((layers, layers))\n",
    "\n",
    "    # Compute cosine similarity between each pair of tensors in the 'l' dimension\n",
    "    for i in range(layers):\n",
    "        for j in range(layers):\n",
    "            cosine_similarities[i, j] = F.cosine_similarity(\n",
    "                reshaped_tensor[i], reshaped_tensor[j], dim=0\n",
    "            )\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0c8cb-fb7a-42b0-80d5-4544830a12e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_actns_sims = []\n",
    "actns_cos_sims = []\n",
    "single_actns_cos_sims = []\n",
    "results = []\n",
    "\n",
    "generator = torch.Generator('cpu')\n",
    "generator.manual_seed(19943434)\n",
    "for prompt in test_prompts_expt:\n",
    "    out, encoder_actns, actns, single_actns = pipe(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=50,\n",
    "        max_sequence_length=256,\n",
    "        guidance_scale=3.5,\n",
    "        return_dict=True,\n",
    "        layer_order=list(range(len(expt_transformer.joint_transformer_blocks))),\n",
    "        single_layer_order=list(range(len(expt_transformer.single_transformer_blocks))),\n",
    "        generator=generator,\n",
    "        track_activations=True\n",
    "    )\n",
    "    results.append((prompt, out.images[0]))\n",
    "    encoder_actns_sims.append(cosine_similarity(encoder_actns))\n",
    "    actns_cos_sims.append(cosine_similarity(actns))\n",
    "    single_actns_cos_sims.append(cosine_similarity(single_actns))\n",
    "    del encoder_actns\n",
    "    del actns\n",
    "    del single_actns\n",
    "\n",
    "# encoder_actns_sims = torch.mean(torch.stack(encoder_actns_sims, dim=0),dim=0)\n",
    "# actns_cos_sims = torch.mean(torch.stack(actns_cos_sims, dim=0),dim=0)\n",
    "# single_actns_cos_sims = torch.mean(torch.stack(single_actns_cos_sims, dim=0),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc82ddd-9669-48b9-bf66-5798a020bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(torch.mean(torch.stack(encoder_actns_sims),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f95e31-6329-4068-9569-552660d24fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(torch.mean(torch.stack(actns_cos_sims),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351069f5-492a-4f43-b7ea-90f708269ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(torch.mean(torch.stack(single_actns_cos_sims),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e599e-231e-481c-b703-e94e1aed62dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_image_grid(results, rows=5,cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d31fec-6743-4416-aa4b-e3c80e31be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle layers seem to be from 5 to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70492a93-5c63-4bf9-8aaf-bce832cd29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(expt_transformer.joint_transformer_blocks)\n",
    "N = len(expt_transformer.single_transformer_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfc418-23a4-422d-9811-0d485b364829",
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f19c5a-3ac9-4b9d-a63c-24288b51cc59",
   "metadata": {},
   "source": [
    "## Skipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572e17b-44a6-42ed-93f7-28e190699c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [0,1,3]\n",
    "single_layer_order = list(range(N))\n",
    "results_skip_layer_middle = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping one joint layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df25ec-5598-4afb-a57c-907a0adc2800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [1,2,3]\n",
    "single_layer_order = list(range(N))\n",
    "results_skip_layer_first = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping first joint layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7cba16-4826-4844-a645-cbe1e1357564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [0,1,2]\n",
    "single_layer_order = list(range(N))\n",
    "results_skip_layer_last = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping last joint layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3b554-5af1-48c1-8fa9-3eba5de9cba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(4,N))\n",
    "results_skip_single_layer_first = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping first 4 single layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac343cc6-39b8-4405-b4f6-c5fc4ab1b9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-2))\n",
    "results_skip_single_layer_last = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping last 2 single layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3ab74-d8f6-4c6b-ab75-02f391a811e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-14)) + list(range(N-11,N))\n",
    "results_skip_single_layer_middle = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping random 3 middle single layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee5356-b41d-4341-af5e-90ec40d1ee49",
   "metadata": {},
   "source": [
    "## Skip Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b771a83-faeb-4aea-a258-09414ed3365a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [0,1,1,3]\n",
    "single_layer_order = list(range(N))\n",
    "results_repeat_layer = test_aura(test_prompts_expt, layer_order, single_layer_order)\n",
    "#skipping first joint layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389dc60-b15c-4dc1-b1f5-aedc458913a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-14)) + [19, 19, 19] + list(range(N-11,N))\n",
    "results_skip_single_layer_middle_repeat = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0fda0-99ce-4793-8da5-b5e8bb73cb48",
   "metadata": {},
   "source": [
    "## Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a76927-7510-43a5-ab39-289ed68600f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [0,2,1,3]\n",
    "single_layer_order = list(range(N))\n",
    "results_skip_reverse_layer = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e274f5-3df1-4bf2-93a9-177fbfe3f53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-14)) + [20, 19, 18] + list(range(N-11,N))\n",
    "results_single_layer_middle_reverse = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95f77f-cf91-4919-bf2f-cb0505cbf876",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137fb52-4c9b-4934-b40e-0c2526eb458c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = [0, (1,2), 3]\n",
    "single_layer_order = list(range(N))\n",
    "results_parallel_layer = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bee1c-f13f-42ba-9712-28c1264406ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-14)) + [(18, 19, 20)] + list(range(N-11,N))\n",
    "results_parallel_single_layer = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32669c3-c57b-44fe-b977-cf1deb4f922e",
   "metadata": {},
   "source": [
    "## Looped-Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98caef46-a083-4fa1-8130-35c8627c9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = [0, (1,2), (1,2), 3]\n",
    "single_layer_order = list(range(N))\n",
    "results_parallel_layer_loop = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035d276-6674-45ed-8dfb-49fccef2bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = list(range(M))\n",
    "single_layer_order = list(range(N-14)) + [(18, 19, 20)] * 3 + list(range(N-11,N))\n",
    "results_parallel_single_layer_loop = test_aura(test_prompts_expt, layer_order, single_layer_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7526aca-b4f3-4a3a-81c0-efbfc22f2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_similarity_matrices\n",
    "plot_similarity_matrices(\n",
    "    [\n",
    "        torch.mean(torch.stack(encoder_actns_sims),dim=0),\n",
    "        torch.mean(torch.stack(actns_cos_sims),dim=0),\n",
    "        torch.mean(torch.stack(single_actns_cos_sims),dim=0)\n",
    "    ],\n",
    "    [\n",
    "        \"Encoder hidden state activations - MMDiT layers\",\n",
    "        \"Hidden state activations - MMDiT layers\",\n",
    "        \"Hidden state activations - Single layers\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bf4e2-a601-456d-b23f-9323437377dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "import textwrap\n",
    "prompts = []\n",
    "images = []\n",
    "titles = [\n",
    "    \"Baseline\", \"Execute middle MMDiT layers in looped parallel\", \"Execute some middle single layers in looped parallel\"\n",
    "]\n",
    "for item in zip(\n",
    "        results,\n",
    "        results_parallel_layer_loop,\n",
    "        results_parallel_single_layer_loop,\n",
    "    ):\n",
    "    prompts.append(item[0][0])\n",
    "    images.append([i[1] for i in item])\n",
    "\n",
    "num_rows = len(prompts)\n",
    "num_cols = len(images[0])\n",
    "fig, axes = pyplot.subplots(num_rows, num_cols, figsize=(20, 25), constrained_layout=True)\n",
    "\n",
    "# Plot the images in the grid\n",
    "for i, row_images in enumerate(images):\n",
    "    for j, image in enumerate(row_images):\n",
    "        axes[i, j].imshow(image)  # Display the image\n",
    "        axes[i, j].axis('off')  # Hide the axes\n",
    "        if i == 0:\n",
    "            axes[0,j].set_title(titles[j], fontsize=16)\n",
    "    # wrapped_text = \"\\n\".join(textwrap.wrap(prompts[i], width=200))\n",
    "    # # Set the row title by merging the column cells\n",
    "    # axes[i, num_cols // 2 - 1].set_title(wrapped_text, fontsize=16, pad=0)\n",
    "\n",
    "# Adjust layout\n",
    "# pyplot.show()\n",
    "pyplot.savefig('aura_six.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
